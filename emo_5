#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed May  8 15:31:43 2019

@author: luy1
"""

import numpy as np
import pandas as pd
import xgboost as xgb

from sklearn.model_selection import train_test_split

train = pd.read_csv('train_cat.csv')
test = pd.read_csv('test_cat.csv')

pd.set_option('display.max_columns', 12)


X = train.loc[:, ['Pclass', 'Sex', 'Age', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize']]
y = train.loc[:, 'Survived']


#one-hot-encoding
X_ohe = pd.get_dummies(X)


#split into training and testing
X_train, X_valid, y_train, y_valid = train_test_split(X_ohe, y, test_size = 0.2, random_state = 2019)

data_dmx = xgb.DMatrix(data = X_ohe, label = y)

train_dmx = xgb.DMatrix(data = X_train, label = y_train)
valid_dmx = xgb.DMatrix(data = X_valid, label = y_valid)


params_ = {'objective': 'binary:logistic', 'eval_metric': ['auc']}

#model1: xgb.cv()
#model2: xgb.train()

mod1 = xgb.cv(params = params_,
              dtrain = data_dmx,
              num_boost_round = 5000,
              early_stopping_rounds = 10,
              nfold = 10,
              verbose_eval = 10)



mod2 = xgb.train(params = params_,
                 dtrain = train_dmx,
                 num_boost_round = 5000,
                 early_stopping_rounds = 10,
                 evals = [(train_dmx, 'training'), (valid_dmx, 'validation')],
                 verbose_eval = 10)




















